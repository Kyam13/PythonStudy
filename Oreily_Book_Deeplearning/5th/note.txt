誤差逆伝搬法
  NNの重みパラメータの勾配は数値微分
  ー＞簡易だが計算に時間がかかる。。。
    ＝＞誤差逆播法
    グラフでこいつを理解していく
    グラフはほんで見てみてください
    グラフを書く際に左から右へ進めるというステップは、順方向の伝搬、略して、順伝播という
    それの逆が逆伝播
      逆伝播は微分を計算するにおいて、重要である

  今回は、例題が多いので、要点だけまとめました。

  局所的な計算
    計算グラフの特徴：「局所的な計算」を伝播することによって最終的な結果を得ることができる点
    局所的ー＞自分に関係する小さな範囲
    つまり、局所的な計算に集中できる。
    端的にいえば、どんな複雑な作業でも、１つ１つは局所的な計算である。

  計算グラフ
    利点：どんな難しい計算でも局所的な計算ができる。
    　　　途中の計算の結果を保持することができる。
    　　　順伝播と逆伝播によって、書く変数の微分の値を効率よく求められることができる。

  連鎖律
    局所的な微分を伝達する原理は、連鎖律に夜もの

  計算グラフの逆伝播
    信号Eに対して、ノードの局所的な微分を乗算して、それを次のノードへ伝える。
    この計算を行うと、目的とする微分の値を効率よく求めることができるのが逆伝播のポイント
    それができる理由として、連鎖律の原理から説明できる

  連鎖律とは
    ある関数が合成関数で表せる場合、その合成関数の微分は、合成関数を
    構成するそれぞれあの関数の微分の籍によって表すことができる、

  連鎖律と計算グラフ
    計算グラフに注目してみると、逆伝播が行なっていることは、連鎖律の原理から構成されている
    よって関係があると言える。

  逆伝播の仕組み
    加算ノードの逆伝播
      １を乗算するだけなので、入力された値をそのまま次のノーへ流すだけになる

    乗算のノード逆伝播
      上流のあ大尉に順伝播の際の入力信号を”ひっくり返した値”を乗算して下流に流します
      ひっくり返した値　編微分した値ときもう１つの変数になってしまうということ。
    りんごの例
      まとめると加算ノードの逆伝播は、そのまま入力に対して同じ値を次のノードに受け渡す。
      乗算ノードの逆伝播は、ノードの中身とひっくり返した変数の値を乗算したものを次のノードに受け渡す

  単純なレイヤの実装
    乗算レイヤの実装
    cho5/layer_naive.pyを参照
    class MulLayer:
      def __init__(self):
          self.x = None
          self.y = None

      def forward(self, x, y):
          self.x = x
          self.y = y
          out = x * y

          return out

      def backward(self, dout):
          dx = dout * self.y
          dy = dout * self.x

          return dx, dy


    class AddLayer:
      def __init__(self):
          pass

      def forward(self, x, y):
          out = x + y

          return out

      def backward(self, dout):
          dx = dout * 1
          dy = dout * 1

          return dx, dy
